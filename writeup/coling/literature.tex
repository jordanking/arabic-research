\section{Related Literature}
\label{sec:literature}

Word embeddings have gained popularity over the past few years since Mikolov et al. published the Word2vec algorithms in 2014 \cite{mikolovdist:2013,mikoloveffic:2013}. While new algorithms and applications have received a great amount of research attention, word embeddings are often considered in the English-like language cases. Arabic differs greatly from English in many ways important to natural language processing. An excellent summary of the most important challenges that come with Arabic is provided by Farghaly et al. ~\cite{farghaly:2009}. Al-Rfou et al. computed word embeddings for 100 languages using Wikipedia articles \cite{al:2013}. This work is the closest to ours, as it inspired our system of semantic and syntactic evaluation. However, we believe our use of a semantic similarity task provides a better quantitative evaluation. Additionally, Farghaly et al. does not actually look at Arabic-specific training methods, while we are focused on specifically improving Arabic embedding quality. Zirikly et al. utilized Arabic word vectors to improve named-entity recognition performance, normalizing hamzas, elongated words, and number normalization \cite{zirikly:2015}. However, this work did not seek out any further improvements for training Arabic word vectors. Belinkov et al. utilize Arabic word vectors in a question answering task, reporting slight improvements when their training data was lemmatized using MADAMIRA \cite{belinkov:2015}. Further normalization is not performed in their work. Some research has been done to utilize morphology to alter the training algorithms of English word embeddings to learn morphological similarities \cite{luong2013better}, but that work makes no attempt to extend the method beyond English. It is also focused on utilizing morphological similarities within a language rather than overcome morphological complexity that exists in a language as morphologically complex as Arabic. In summary, Arabic word vectors are being used, but the process of training them has not been explored or optimized as we aim to do with this work.

In English, there are some accessible open source natural language processing tools, especially those made available through Stanford University \cite{manning-EtAl:2014:P14-5}. However in Arabic, the list of strong NLP tools is a bit shorter. Habash et al. developed Mada+Tokan to perform tokenization, part of speech tagging, and lemmatization \cite{habash:2009}. Diab published the Amira software as fast and robust option for phrase chunking and POS tagging \cite{diab:2009}. Recently, these tools have been brought together into the MADAMIRA software package, comprised of a suite of Arabic NLP tools that includes tokenization, lemmatization, phrase chunking, and part of speech tagging \cite{pasha:2014}. 
% While powerful and robust, MADAMIRA's lack of open source code and inaccessible input and output make it difficult to use in short NLP experiment scripts. Our python package provides a wrapper to help with this difficulty, providing simple calls to process and access commonly desired output from MADAMIRA.

Word similarity tasks are widely used for NLP experimentation and evaluation, and a long list of semantic similarity data was compiled by Faruqui et al. \cite{faruqui:2014}. However, few of these are available in Arabic. Faruqui refers to two data sets that have been translated to Arabic by Hassan et al. \cite{hassan:2009}, the 353 word WordSimilarity-353 and the 30 word Miller-Charles datasets \cite{finkelstein:2001,miller:1991}. However, this translation was done by a single Arabic speaker using the English semantic similarity scores \cite{hassan:2009}. In their paper, they cite that with 5 translators on a Spanish task, they obtained unanimous translations 74\% of the time, and further rescoring produced a correlation of .86. Our work attempts to alleviate these losses by beginning with Arabic words and evaluating them all with multiple fluent Arabic speakers.


Word embeddings have been used in many tasks, from sentiment classification to semantic translation. Zhang et al. have shown that word embeddings capture enough information to classify sentiment \cite{zhang2015chinese}. Dickinson et al. have used word embeddings with neural networds to classify the sentiment of tweets related to publicly traded companies such that it correlates with stock prices \cite{dickinson2015sentiment}. By aligning words in corpuses from two languages, Wolf et al. have shown that word embeddings from multiple languages can be used for translation \cite{wolf2014joint}. Beyond these unique applications, word embeddings enable many numerical analysis tools to be applied to text.

% Methods to measure various qualities and phenomena of text are well researched. Our task is fairly unique in its application of word embeddings to measure buzz, but is inspired and influenced by a many well-explored text mining tasks. One of the closest related works to our application of word embeddings for buzz detection is Rekabsaz's work showing improvements in text document querying when using semantic information from word embeddings to retrieve domain specific documents \cite{rekabsazusing}. Other similar work is done in the field of event detection, where trends in text documents are identified with machine learning, data mining, and graph theory \cite{radinsky2012learning}. Similar works develop measures of semantic meaning without the use of word embeddings, using many sources of text to identify events and storylines \cite{Wei:2016}. The buzz application looks at the domain specific retrieval problem in a time series setting similar to event detection.
