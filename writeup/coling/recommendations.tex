\section{Recommendations for Arabic Word Embeddings}
\label{sec:recommendations}

Our results have affirmed that there is universal solution when choosing methods to train Arabic word embeddings. This result supports the findings of Schnabel et al. when they investigated how to evaluate word embeddings and found that different evaluations provided useful but different results \cite{schnabel2015evaluation}. We have shown that within a task different models can offer dramatically different performance. When developing Arabic word embeddings it is beneficial to inspect all preprocessing methods available. However, we do offer some guidelines based on our results.
\\
For preprocessing, we believe that unprocessed Arabic may perform well if it is trained on the same data on which it is applied. Due to the emphasis on syntactic analogies in the analogy task, we suggest trying lemmatization for tasks requiring syntactic analysis. We suspect that it performs well as it reduces complex words to simpler forms the retain their basic syntactic structure. For semantic-heavy analysis, we suggest trying tokenization as it performed so well on the Word Similarity 353 similarity task. Tokenization likely performs well as it does not reduce the text, but isolates each core word in a broken down context. However, we reiterate that we believe it is essential to try at least one model from each of these methods on a specific application, as they have been shown to perform very differently across different tasks.
\\
For normalization, we saw nearly no difference when we removed vowels or normalized numerical digits. For training, we did not find a dominant training algorithm between Skip-Gram and CBOW. However, we do believe the smaller window size of 4 demonstrated significantly better results globally. We also found large improvements on the analogy task for 200 dimensional embeddings and no evidence of draw backs on other tasks. With more data and time, it may be possible to obtain even better performance with 300 dimensions, as the Google News embeddings showed on the analogy task. Other parameters did not show significant improvements on any of the evaluation tasks.