\begin{abstract}
\label{sec:abstract}

Word embeddings are an increasingly important tool for NLP tasks that require semantic understanding of words. Little attention has been given to the production and application of Arabic word embeddings. Arabic is far more morphologically complex than English due to the many conjugations, suffixes, articles, and other grammar constructs. This has a significant effect on the training and application of Arabic word embeddings. While there are a number of techniques to break down Arabic words through lemmatization and tokenization, the quality of resulting word embeddings must be investigated to understand the effects of these transformations. In this paper, we investigate a number of preprocessing methods and training parameterizations to establish guideline methodologies for training high quality Arabic word embeddings. Using various evaluation tasks, including a new semantic similarity task created by fluent Arabic speakers, we are able to identify training strategies that produce high quality results for each task. To summarize, the main contributions of this work include improved methodologies for training Arabic word vectors, a semantic similarity task developed by native Arabic speakers, and a python package of Arabic text processing tools.

\end{abstract}