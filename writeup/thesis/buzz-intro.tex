\chapter{Applying Word Embeddings to Buzz Detection}
\label{sec:buzz}

\section{Buzz Detection Methodology}

The properties of high quality word embeddings can used in unique text mining applications. In this work we apply the best models from our training experiments to a buzz detection task, where we harness the power of Arabic word embeddings to demonstrate their power. We define buzz to be the level of discussion about a semantic topic in a set of documents. We define the buzz detection task as given a set of documents and a topic, accurately identify the level of buzz about the topic within them. Our goal in the buzz task is to detect buzz over a series of months in a set of Arabic news documents relevant to Iraq. We will detect buzz for each month over which we have data, measuring how much buzz about the topic of \textit{violence} is in the news each month. Our ground truth for evaluation is the publicly available Iraq Death Count data from \url{https://www.iraqbodycount.org/database/} that aims to document how many violent deaths occur in Iraq on a monthly basis \cite{IraqB68:online}. We will look at five methods to measure buzz to demonstrate the benefits of using Arabic word embeddings, each outlined in Table \ref{table:buzztypes}. We score the results from each method against the ground truth by finding the Spearman and Pearson correlations between the method's scores and the ground truth counts. Here we would like to note that the task of buzz detection is difficult for a number of reasons. There are many news documents that discuss violence that is not related to violent deaths, the ground truth measure of violent deaths is difficult to collect with perfect accuracy, and the relationship between violent deaths and violent discussions is not clear or linear. With these considerations, we aim only to obtain some notion of correlation between our buzz measure and the ground truth. We propose that we can obtain improved results on the buzz detection task through the use of Arabic word embeddings on this difficult task. Below we outline three baseline buzz detection methods that do not use embeddings and three buzz detection methods that utilize Arabic word embeddings.
\\
Our three baselines for buzz detection are the frequency method, the domain method, and the synonym method. The frequency method is to simply count the number of times the Arabic words for violent or violence occur per month in the corpus, and normalize this score by the total number of words in the corpus per month. The domain method is the same as the frequency method, but we use a list of violence-related Arabic words instead of just violent and violence. This list of words in the violence domain is provided by experts on social science in the Middle East. The synonym method expands this domain list by adding 5 synonyms obtained from a thesaurus (through translation) for every expert provided word. When expanding words in this way, we only keep the intersection of each of these expansions leaving us with $|expanded set| \leq |original set| * 6$. The similarity method expands the domain method by using the 5 most similar word embeddings to the word embedding for each word in the expert domain list. The weighted similarity method adds weights to each word in the similarity method by how similar it is to the word embedding for the original expert-provided word. The method that we propose to fully harness the power of Arabic word embeddings is to take the average similarity of each word in the corpus to our original domain. We call this method mean similarity. All methods that use word embeddings are evaluated with three different models to demonstrate differences between training methods. The three models are the top performing models on the Word Similarity 353 task, our similarity task, and the analogy task. This provides us with representation for each of the three preprocessing methods.

\begin{table}
\begin{center}
\begin{tabular}{l|l|l|l}
\textbf{Type} & \textbf{Target Words} & \textbf{Uses Embeddings} & \textbf{Weighted} \\
\hline
$frequency$ & \textit{violent, violence} & No & No \\
$domain$ & \textit{expert domain} & No & No \\
$synonym$ & \textit{expert domain + synonyms} & No & No \\
$similarity$ & \textit{expert domain + similar embeddings} & Yes & No \\
$weighted$ & \textit{expert domain + similar embeddings} & Yes & Yes \\
$mean similarity$ & \textit{violence} & Yes & Yes \\
\end{tabular}
\caption{Methods to Measure Buzz}
\label{table:buzztypes}
\end{center}
\end{table}

\section{Buzz Detection Experiments}
\label{sec:experiments-buzz}

Table \ref{table:buzzresults} shows the correlations between each of our buzz methods and the ground truth values. Of the methods that do not use word embeddings, we can see that only the domain method acheives a positive spearman correlation. The frequency of the word violent shows no correlation, and the synonym expansion adds enough noise to reduce our expert domain correlation back to zero. These results imply that the expert domain frequency buzz is sufficient to rank the months in order of violence, but the values of the domain buzz measure do no show any numerical Pearson correlation with the ground truth. The first two buzz methods using embeddings do not change the results of the expert domain method. This is largely due to the lack of adding new words, as the expert domain is already a large set of similar words. However, the full mean embedding similarity method shows more promise. Not only do all three embedding models provide positive Spearman rank correlation, the base embedding model with this method performs better than the expert domain frequency method, using only the seed topic word of violence! This also reinforces the results in our work on training embeddings, showing that the performance between differently trained models varies greatly. Furthermore, the mean embedding buzz method obtains a positive Pearson correlation with the ground truth values. This implies that the mean embedding buzz scores numerically correlate with the ground truth death counts. This result is extremely useful, as even the slightest correlation here implies that we were able to detect and measure the buzz about violence in this set of Arabic news articals. In this experiment we have shown how Arabic word embeddings can be used to solve a text mining task that other methods, even human domain experts, can struggle with.


\begin{table}
\begin{center}
\begin{tabular}{l|l|l|l}
\bfseries Method & \bfseries Model & \bfseries Buzz & \bfseries Normalized Buzz
\csvreader[head to column names]{results_buzz/masterPrepared.csv}{}
{\\\hline\csvcoli&\csvcolii&\csvcoliii&\csvcoliv}
\end{tabular}
\caption{Correlation Scores Between Method Scores and Ground Truth}
\label{table:buzzresults}
\end{center}
\end{table}












