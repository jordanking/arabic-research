\section{Introduction}

We are researching methods to create Arabic word embeddings, which are numerical representations of a given word’s meaning - both semantic meaning and syntactic meaning.
These embeddings are obtained using machine learning algorithms that utilize the context a word appears in to infer its meaning.
This works very well as words with similar meanings tend to be used in similar contexts.
For example "I eat bread every night" and "I eat rice every night" is an example of how foods may appear in similar contexts.
With enough text to process, we can train numerical vectors to learn that bread and rice appear in these "common-for-food" contexts.
Similarly, we can learn syntactic relationships as different parts of speech appear in certain context patterns as well.
\\
The end result of having good word embeddings is that we have a representation of the meaning of a word, without ever translating or looking at a dictionary of meanings. 
We can harvest the semantic and syntactic meaning straight from a corpus of natural written language. 
With accurate word embeddings, we can perform neat and useful operations to investigate the relationships between words.
To list a few of these operations, we can measure the similarity of two words, identify which word from a set is least similar, and solve basic analogies.
The classic party trick for word embeddings is to take (the numerically embeddings of) king, subtract man, and add woman.
The resulting embedding is closest to the embedding for queen!
Intuitively, this allows us to subtract the male gender meaning from king’s embedding, add the female gender meaning, and end up with an embedding equivalent to queen’s embedding.
\\
More about the algorithms and uses: https://code.google.com/p/word2vec/
\\
We would like accurate Arabic word embeddings so we can interpret the general topics of discussion in Arabic media without using translation or ignoring some words belonging to a topic.
Specifically, one task we are using the embeddings for is to learn what words are highly similar to words such as fear (in Arabic), and then compute the degree to which some media is using these words similar to fear in the context of some city.
This information may help us predict when people will be forced to migrate from the city.