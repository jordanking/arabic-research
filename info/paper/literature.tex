\section{Related Literature}
\label{sec:literature}

Word embeddings have gained popularity over the past few years since Mikolov et al. published the word2vec algorithms in 2014 \cite{mikolovdist:2013, mikoloveffic:2013}. While new algorithms and applications have received a great amount of research attention, word embeddings are often considered in the English-like language cases. Arabic differs greatly from English in many ways important to natural language processing. An excellent summary of the most important challenges that come with Arabic is provided by Farghaly et al. ~\cite{farghaly:2009}. Al-Rfou et al. computed word embeddings for 100 languages using Wikipedia articles \cite{al:2013}. This work inspired our system of semantic and syntactic evaluation, but we believe our use of a semantic similarity task provides a better quantitative evaluation. Additionally, this work does not actually look at Arabic-specific training methods. Zirikly et al. utilized Arabic word vectors to improve named-entity recognition performance, normalizing hamzas, elongated words, and number normalization \cite{zirikly:2015}. However, this work did not seek out any further improvements for training Arabic word vectors. Belinkov et al. utilize Arabic word vectors in a question answering task, reporting slight improvements when their training data was lemmatized using Madamira \cite{belinkov:2015}. Further normalization is not performed in their work. In summary, Arabic word vectors are being used, but the process of training them has not been explored or optimized as we aim to do with this work.
\\
In English, there are some accessible open source natural language processing tools, especially those made available through Stanford University. However in Arabic, the list of strong NLP tools is a bit shorter. Habash et al. developed Mada+Tokan to perform tokenization, part of speech tagging, and lemmatization \cite{habash:2009}. Diab published the Amira software as fast and robust option for phrase chunking and POS tagging \cite{diab:2009}. Recently, these tools have been brought together into the Madamira software package, comprised of a suite of Arabic NLP tools that includes tokenization, lemmatization, phrase chunking, and part of speech tagging \cite{pasha:2014}. While powerful and robust, Madamira's lack of open source code and inaccessible input and output make it difficult to use in short NLP experiment scripts. Our python package provides a wrapper to help with this difficulty, providing simple calls to process and access commonly desired output from Madamira.
\\
Word similarity tasks are widely used for NLP experimentation and evaluation, and a long list of semantic similarity data was compiled by Faruqui et al. \cite{faruqui:2014}. However, few of these are available in Arabic. Faruqui refers to two data sets that have been translated to Arabic by Hassan et al. \cite{hassan:2009}, the 353 word WordSimilarity-353 and the 30 word Miller-Charles datasets \cite{finkelstein:2001,miller:1991}. however this translation was done by a single Arabic speaker using the English semantic similarity scores \cite{hassan:2009}. In their paper, they cite that with 5 translators on a Spanish task, they obtained unanimous translations 74\% of the time, and further rescoring produced a correlation of .86. Our work attempts to alleviate these losses by beginning with Arabic words and evaluating them all with multiple fluent Arabic speakers.