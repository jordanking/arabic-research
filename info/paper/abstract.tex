\section*{Abstract}

Word embeddings are an increasingly important tool for NLP tasks, especially those that require semantic understanding of words.
Methodologies and properties of English word embeddings have been extensively researched, however little attention has been given to the production and application of Arabic word embeddings.
Arabic is far more morphologically complex than English due to the many conjugations, suffixes, articles, and other grammar constructs.
Arabic words in text are often carry more contextual information about objects, tense, gender, and definiteness than English, meaning that Arabic unigrams occur less frequently on average than English unigrams.
This has a significant effect on the training and application of Arabic word embeddings, as the embeddings are trained on unigram tokens.
While there are a number of techniques to break down Arabic words through lemmatization and tokenization, the quality of resulting word embeddings must be investigated to understand the effects of these transformations.
In this work, we investigate a number of preprocessing methods and training parameterizations to establish best practice strategies for training Arabic word embeddings.
To enable this research, we required a semantic similarity task to evaluate the Arabic word embeddings.
There is little work done to provide a large semantic similarity task in Arabic so we created a list of 1000 similarity scores for given Arabic word pairs using native Arabic speakers.
We evaluated all training parameterizations by using the embeddings from a given parameterization to obtain a similarity score to evaluate against the task.
Additionally, we evaluated the word embeddings' ability to capture syntactic properties of words using a part of speech tagging task.
Using these tasks, we were able to identify the training strategies that produce the best results for each task.
We also offer a suite of Arabic NLP tools developed alongside this work that helps fill the void of accessible open source Arabic NLP tools.
Altogether, this work provides best practices for training Arabic word vectors, an open semantic similarity task developed by native Arabic speakers, and a python package of Arabic text processing tools.